{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:38.733468Z",
     "start_time": "2020-06-19T17:12:36.808442Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import requests\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:39.990710Z",
     "start_time": "2020-06-19T17:12:39.984093Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ## For multi-gpu setups, select secondary GPU.\n",
    "    devices = tf.config.get_visible_devices()\n",
    "    gpu_1 = list(filter(lambda d: d.name[-5:] == 'GPU:1',devices))[0]\n",
    "    tf.config.set_visible_devices(gpu_1, 'GPU')\n",
    "except:\n",
    "    # handle situations where there is < 2 GPUs.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:47.868049Z",
     "start_time": "2020-06-19T17:12:46.182779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download MNIST digits dataset.\n",
    "\n",
    "train_images_url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "train_labels_url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "test_images_url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "urls = [train_images_url, train_labels_url, test_images_url, test_labels_url]\n",
    "\n",
    "def dl_file(url, destdir='.'):\n",
    "    if not os.path.exists(destdir):\n",
    "        os.mkdir(destdir)\n",
    "\n",
    "    dest_path = os.path.join(destdir,os.path.basename(url))\n",
    "    if not os.path.exists(dest_path):\n",
    "        r = requests.get(url)\n",
    "        with open(dest_path, 'wb') as outfile:\n",
    "            outfile.write(r.content)\n",
    "\n",
    "for url in urls:\n",
    "    dl_file(url, destdir='mnist-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:47.883189Z",
     "start_time": "2020-06-19T17:12:47.873452Z"
    }
   },
   "outputs": [],
   "source": [
    "# IDX file reader\n",
    "\n",
    "class IDX_File(object):\n",
    "    # class constants\n",
    "    bytecode_type_map_names = {\n",
    "        0x08: 'unsigned byte',\n",
    "        0x09: 'signed byte',\n",
    "        0x0B: 'short (2 bytes)',\n",
    "        0x0C: 'int (4 bytes)',\n",
    "        0x0D: 'float (4 bytes)',\n",
    "        0x0E: 'double (8 bytes)'\n",
    "    }\n",
    "    bytecode_type_map = {\n",
    "        0x08: np.ubyte,\n",
    "        0x09: np.byte,\n",
    "        0x0B: np.short,\n",
    "        0x0C: np.intc,\n",
    "        0x0D: np.single,\n",
    "        0x0E: np.double,\n",
    "    }\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        with gzip.open(filepath, 'rb') as infile:\n",
    "            if int.from_bytes(infile.read(2), 'big') != 0:\n",
    "                raise RuntimeError(\"Improperly formatted IDX file. First two bytes should be 0.\")\n",
    "\n",
    "            self.data_type = int.from_bytes(infile.read(1), 'big')\n",
    "            self.num_dimensions = int.from_bytes(infile.read(1), 'big')\n",
    "            dimensions = []\n",
    "            for i in range(self.num_dimensions):\n",
    "                dimensions.append(int.from_bytes(infile.read(4), 'big'))\n",
    "\n",
    "            total_len = 1\n",
    "            for dim_len in dimensions:\n",
    "                total_len *= dim_len\n",
    "\n",
    "            itemsize = np.dtype(IDX_File.bytecode_type_map[self.data_type]).itemsize\n",
    "            self.data = np.frombuffer(infile.read(itemsize*total_len), dtype=IDX_File.bytecode_type_map[self.data_type])\n",
    "            self.data = self.data.reshape(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:49.552660Z",
     "start_time": "2020-06-19T17:12:48.883341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read MNIST digits\n",
    "train_images_idx_file = IDX_File('mnist-data/train-images-idx3-ubyte.gz')\n",
    "train_labels_idx_file = IDX_File('mnist-data/train-labels-idx1-ubyte.gz')\n",
    "\n",
    "test_images_idx_file = IDX_File('mnist-data/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_idx_file = IDX_File('mnist-data/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Unpack mnist digits and make one-hot labels\n",
    "train_X = train_images_idx_file.data.astype(np.float)\n",
    "train_X = train_X/256.\n",
    "train_Y = np.zeros((train_labels_idx_file.data.size, train_labels_idx_file.data.max()+1))\n",
    "train_Y[np.arange(train_labels_idx_file.data.size), train_labels_idx_file.data] = 1\n",
    "\n",
    "test_X = test_images_idx_file.data.astype(np.float)\n",
    "test_X = test_X/256.\n",
    "test_Y = np.zeros((test_labels_idx_file.data.size, test_labels_idx_file.data.max()+1))\n",
    "test_Y[np.arange(test_labels_idx_file.data.size), test_labels_idx_file.data] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:50.110029Z",
     "start_time": "2020-06-19T17:12:50.099372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5./6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:12:53.589238Z",
     "start_time": "2020-06-19T17:12:53.581661Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_test_model(name, model, val_split, train_X, train_Y, test_X, test_Y, epochs=10, callbacks=[]):\n",
    "    num_train_total = train_X.shape[0]\n",
    "    num_train = int(num_train_total*val_split)\n",
    "    \n",
    "    model.fit(train_X[:num_train], train_Y[:num_train], validation_data=(train_X[num_train:], train_Y[num_train:]), epochs=epochs, callbacks=callbacks)\n",
    "    error_rate = sum(model.predict(test_X).argmax(axis=1)!=test_Y.argmax(axis=1))/test_X.shape[0]\n",
    "    \n",
    "    print(\"{} Error Rate: {:.2f}%\".format(name, error_rate*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:13:31.611914Z",
     "start_time": "2020-06-19T17:12:53.740468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.2012 - val_loss: 0.1049\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0827 - val_loss: 0.0829\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0514 - val_loss: 0.0822\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0356 - val_loss: 0.0746\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0261 - val_loss: 0.0890\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0204 - val_loss: 0.0996\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0177 - val_loss: 0.0941\n",
      "One Layer Simple Model Error Rate: 2.25%\n"
     ]
    }
   ],
   "source": [
    "# Build tensorflow model.\n",
    "one_layer_simple_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28*28,), input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "one_layer_simple_model.summary()\n",
    "one_layer_simple_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"One Layer Simple Model\", one_layer_simple_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:14:41.264844Z",
     "start_time": "2020-06-19T17:13:31.613342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 12s 241us/sample - loss: 0.1969 - val_loss: 0.1095\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 11s 236us/sample - loss: 0.0876 - val_loss: 0.1013\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 11s 236us/sample - loss: 0.0600 - val_loss: 0.0984\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 11s 240us/sample - loss: 0.0493 - val_loss: 0.1055\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 12s 240us/sample - loss: 0.0369 - val_loss: 0.1104\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 11s 239us/sample - loss: 0.0334 - val_loss: 0.1021\n",
      "Two Layer Simple Model Error Rate: 2.42%\n"
     ]
    }
   ],
   "source": [
    "# Build tensorflow model.\n",
    "two_layer_simple_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28*28,), input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "two_layer_simple_model.summary()\n",
    "two_layer_simple_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"Two Layer Simple Model\", two_layer_simple_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:15:30.316518Z",
     "start_time": "2020-06-19T17:14:41.266365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                216330    \n",
      "=================================================================\n",
      "Total params: 216,650\n",
      "Trainable params: 216,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 170us/sample - loss: 0.1983 - val_loss: 0.0972\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.0739 - val_loss: 0.0794\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.0504 - val_loss: 0.0733\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 8s 166us/sample - loss: 0.0377 - val_loss: 0.0776\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.0283 - val_loss: 0.0870\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 8s 167us/sample - loss: 0.0204 - val_loss: 0.0793\n",
      "One Layer CNN Model Error Rate: 2.13%\n"
     ]
    }
   ],
   "source": [
    "one_layer_cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "one_layer_cnn_model.summary()\n",
    "one_layer_cnn_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"One Layer CNN Model\", one_layer_cnn_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T17:21:20.928244Z",
     "start_time": "2020-06-19T17:15:30.317917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 125)               1152125   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1260      \n",
      "=================================================================\n",
      "Total params: 1,172,201\n",
      "Trainable params: 1,172,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 39s 814us/sample - loss: 0.2210 - val_loss: 0.0569\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 39s 808us/sample - loss: 0.0931 - val_loss: 0.0492\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 39s 807us/sample - loss: 0.0676 - val_loss: 0.0435\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 39s 807us/sample - loss: 0.0567 - val_loss: 0.0405\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 39s 803us/sample - loss: 0.0461 - val_loss: 0.0396\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 39s 804us/sample - loss: 0.0397 - val_loss: 0.0383\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 39s 806us/sample - loss: 0.0359 - val_loss: 0.0399\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 39s 806us/sample - loss: 0.0294 - val_loss: 0.0390\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 39s 807us/sample - loss: 0.0291 - val_loss: 0.0385\n",
      "Three Layer CNN Model Error Rate: 0.83%\n"
     ]
    }
   ],
   "source": [
    "# Model from https://towardsdatascience.com/a-simple-2d-cnn-for-mnist-digit-recognition-a998dbc1e79a\n",
    "three_layer_cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(125, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_model.summary()\n",
    "three_layer_cnn_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"Three Layer CNN Model\", three_layer_cnn_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

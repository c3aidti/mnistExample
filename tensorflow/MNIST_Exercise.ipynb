{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import requests\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ## For multi-gpu setups, select secondary GPU.\n",
    "    devices = tf.config.get_visible_devices()\n",
    "    gpu_1 = list(filter(lambda d: d.name[-5:] == 'GPU:1',devices))[0]\n",
    "    tf.config.set_visible_devices(gpu_1, 'GPU')\n",
    "except:\n",
    "    # handle situations where there is < 2 GPUs.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST digits dataset.\n",
    "\n",
    "train_images_url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "train_labels_url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "test_images_url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "urls = [train_images_url, train_labels_url, test_images_url, test_labels_url]\n",
    "\n",
    "def dl_file(url, destdir='.'):\n",
    "    if not os.path.exists(destdir):\n",
    "        os.mkdir(destdir)\n",
    "\n",
    "    dest_path = os.path.join(destdir,os.path.basename(url))\n",
    "    if not os.path.exists(dest_path):\n",
    "        r = requests.get(url)\n",
    "        with open(dest_path, 'wb') as outfile:\n",
    "            outfile.write(r.content)\n",
    "\n",
    "for url in urls:\n",
    "    dl_file(url, destdir='mnist-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDX file reader\n",
    "\n",
    "class IDX_File(object):\n",
    "    # class constants\n",
    "    bytecode_type_map_names = {\n",
    "        0x08: 'unsigned byte',\n",
    "        0x09: 'signed byte',\n",
    "        0x0B: 'short (2 bytes)',\n",
    "        0x0C: 'int (4 bytes)',\n",
    "        0x0D: 'float (4 bytes)',\n",
    "        0x0E: 'double (8 bytes)'\n",
    "    }\n",
    "    bytecode_type_map = {\n",
    "        0x08: np.ubyte,\n",
    "        0x09: np.byte,\n",
    "        0x0B: np.short,\n",
    "        0x0C: np.intc,\n",
    "        0x0D: np.single,\n",
    "        0x0E: np.double,\n",
    "    }\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        with gzip.open(filepath, 'rb') as infile:\n",
    "            if int.from_bytes(infile.read(2), 'big') != 0:\n",
    "                raise RuntimeError(\"Improperly formatted IDX file. First two bytes should be 0.\")\n",
    "\n",
    "            self.data_type = int.from_bytes(infile.read(1), 'big')\n",
    "            self.num_dimensions = int.from_bytes(infile.read(1), 'big')\n",
    "            dimensions = []\n",
    "            for i in range(self.num_dimensions):\n",
    "                dimensions.append(int.from_bytes(infile.read(4), 'big'))\n",
    "\n",
    "            total_len = 1\n",
    "            for dim_len in dimensions:\n",
    "                total_len *= dim_len\n",
    "\n",
    "            itemsize = np.dtype(IDX_File.bytecode_type_map[self.data_type]).itemsize\n",
    "            self.data = np.frombuffer(infile.read(itemsize*total_len), dtype=IDX_File.bytecode_type_map[self.data_type])\n",
    "            self.data = self.data.reshape(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MNIST digits\n",
    "train_images_idx_file = IDX_File('mnist-data/train-images-idx3-ubyte.gz')\n",
    "train_labels_idx_file = IDX_File('mnist-data/train-labels-idx1-ubyte.gz')\n",
    "\n",
    "test_images_idx_file = IDX_File('mnist-data/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_idx_file = IDX_File('mnist-data/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Unpack mnist digits and make one-hot labels\n",
    "train_X = train_images_idx_file.data.astype(np.float)\n",
    "train_X = train_X/256.\n",
    "train_Y = np.zeros((train_labels_idx_file.data.size, train_labels_idx_file.data.max()+1))\n",
    "train_Y[np.arange(train_labels_idx_file.data.size), train_labels_idx_file.data] = 1\n",
    "\n",
    "test_X = test_images_idx_file.data.astype(np.float)\n",
    "test_X = test_X/256.\n",
    "test_Y = np.zeros((test_labels_idx_file.data.size, test_labels_idx_file.data.max()+1))\n",
    "test_Y[np.arange(test_labels_idx_file.data.size), test_labels_idx_file.data] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5./6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(name, model, val_split, train_X, train_Y, test_X, test_Y, epochs=10, callbacks=[]):\n",
    "    num_train_total = train_X.shape[0]\n",
    "    num_train = int(num_train_total*val_split)\n",
    "    \n",
    "    model.fit(train_X[:num_train], train_Y[:num_train], validation_data=(train_X[num_train:], train_Y[num_train:]), epochs=epochs, callbacks=callbacks)\n",
    "    error_rate = sum(model.predict(test_X).argmax(axis=1)!=test_Y.argmax(axis=1))/test_X.shape[0]\n",
    "    \n",
    "    print(\"{} Error Rate: {:.2f}%\".format(name, error_rate*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_40 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.2064 - val_loss: 0.1177\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0816 - val_loss: 0.0897\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0520 - val_loss: 0.0768\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0350 - val_loss: 0.0792\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0271 - val_loss: 0.0939\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.0215 - val_loss: 0.1102\n",
      "One Layer Simple Model Error Rate: 2.20%\n"
     ]
    }
   ],
   "source": [
    "# Build tensorflow model.\n",
    "one_layer_simple_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28*28,), input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "one_layer_simple_model.summary()\n",
    "one_layer_simple_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"One Layer Simple Model\", one_layer_simple_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_41 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1935 - val_loss: 0.1418\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.0851 - val_loss: 0.1772\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.0638 - val_loss: 0.0914\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.0466 - val_loss: 0.1092\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.0383 - val_loss: 0.1245\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0340 - val_loss: 0.1243\n",
      "Two Layer Simple Model Error Rate: 2.36%\n"
     ]
    }
   ],
   "source": [
    "# Build tensorflow model.\n",
    "two_layer_simple_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28*28,), input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "two_layer_simple_model.summary()\n",
    "two_layer_simple_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"Two Layer Simple Model\", two_layer_simple_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_43 (Reshape)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                216330    \n",
      "=================================================================\n",
      "Total params: 216,650\n",
      "Trainable params: 216,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.1890 - val_loss: 0.0875\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0676 - val_loss: 0.0732\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.0473 - val_loss: 0.0698\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0346 - val_loss: 0.0808\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.0267 - val_loss: 0.0828\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0199 - val_loss: 0.0953\n",
      "One Layer CNN Model Error Rate: 1.87%\n"
     ]
    }
   ],
   "source": [
    "one_layer_cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "one_layer_cnn_model.summary()\n",
    "one_layer_cnn_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"One Layer CNN Model\", one_layer_cnn_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_44 (Reshape)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 125)               1152125   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                1260      \n",
      "=================================================================\n",
      "Total params: 1,172,201\n",
      "Trainable params: 1,172,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2184 - val_loss: 0.0558\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0914 - val_loss: 0.0513\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0710 - val_loss: 0.0464\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0563 - val_loss: 0.0421\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0474 - val_loss: 0.0358\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0400 - val_loss: 0.0439\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0363 - val_loss: 0.0422\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0317 - val_loss: 0.0396\n",
      "Three Layer CNN Model Error Rate: 0.92%\n"
     ]
    }
   ],
   "source": [
    "# Model from https://towardsdatascience.com/a-simple-2d-cnn-for-mnist-digit-recognition-a998dbc1e79a\n",
    "three_layer_cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(125, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "three_layer_cnn_model.summary()\n",
    "three_layer_cnn_model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=3)\n",
    "]\n",
    "\n",
    "train_and_test_model(\"Three Layer CNN Model\", three_layer_cnn_model, 0.8, train_X, train_Y, test_X, test_Y, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
